{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/vikram/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vikram/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/vikram/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in /Users/vikram/opt/anaconda3/lib/python3.9/site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: nltk>=3.8 in /Users/vikram/opt/anaconda3/lib/python3.9/site-packages (from textblob) (3.8.1)\n",
      "Requirement already satisfied: tqdm in /Users/vikram/opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.8->textblob) (4.64.0)\n",
      "Requirement already satisfied: joblib in /Users/vikram/opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.8->textblob) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/vikram/opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.8->textblob) (2022.3.15)\n",
      "Requirement already satisfied: click in /Users/vikram/opt/anaconda3/lib/python3.9/site-packages (from nltk>=3.8->textblob) (8.0.4)\n",
      "Requirement already satisfied: textstat in /Users/vikram/opt/anaconda3/lib/python3.9/site-packages (0.7.3)\n",
      "Requirement already satisfied: pyphen in /Users/vikram/opt/anaconda3/lib/python3.9/site-packages (from textstat) (0.15.0)\n",
      "Requirement already satisfied: Pillow in /Users/vikram/opt/anaconda3/lib/python3.9/site-packages (10.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/vikram/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/vikram/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import string\n",
    "from wordcloud import WordCloud\n",
    "!pip install textblob\n",
    "from textblob import TextBlob\n",
    "!pip install textstat\n",
    "import textstat\n",
    "\n",
    "!pip install --upgrade Pillow\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Very nice set. Good quality. We have had the s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating label  \\\n",
       "0  Home_and_Kitchen_5     5.0    CG   \n",
       "1  Home_and_Kitchen_5     5.0    CG   \n",
       "2  Home_and_Kitchen_5     5.0    CG   \n",
       "3  Home_and_Kitchen_5     1.0    CG   \n",
       "4  Home_and_Kitchen_5     5.0    CG   \n",
       "\n",
       "                                               text_  \n",
       "0  Love this!  Well made, sturdy, and very comfor...  \n",
       "1  love it, a great upgrade from the original.  I...  \n",
       "2  This pillow saved my back. I love the look and...  \n",
       "3  Missing information on how to use it, but it i...  \n",
       "4  Very nice set. Good quality. We have had the s...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n",
    "## FEEL FREE TO ADD MULTIPLE CELLS PER SECTION \n",
    "reviews_df = pd.read_csv('/Users/vikram/Documents/COGS108/Group58_SP24/data/fake_reviews.csv')\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting the names of the columns better and changing the ratings column from floats to integers\n",
    "reviews_df = reviews_df.rename(columns = {'text_': 'text'})\n",
    "reviews_df['category'] = reviews_df['category'].apply(lambda s: s[:-2].replace('_', ' '))\n",
    "reviews_df['rating'] = reviews_df['rating'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_no_stop</th>\n",
       "      <th>text_no_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home and Kitchen</td>\n",
       "      <td>5</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
       "      <td>love ! well made , sturdy , comfortable . love...</td>\n",
       "      <td>love this  well made sturdy and very comfortab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home and Kitchen</td>\n",
       "      <td>5</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I...</td>\n",
       "      <td>love , great upgrade original . 've mine coupl...</td>\n",
       "      <td>love it a great upgrade from the original  ive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home and Kitchen</td>\n",
       "      <td>5</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and...</td>\n",
       "      <td>pillow saved back . love look feel pillow .</td>\n",
       "      <td>this pillow saved my back i love the look and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home and Kitchen</td>\n",
       "      <td>1</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it i...</td>\n",
       "      <td>missing information use , great product price !</td>\n",
       "      <td>missing information on how to use it but it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home and Kitchen</td>\n",
       "      <td>5</td>\n",
       "      <td>CG</td>\n",
       "      <td>Very nice set. Good quality. We have had the s...</td>\n",
       "      <td>nice set . good quality . set two months</td>\n",
       "      <td>very nice set good quality we have had the set...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           category  rating label  \\\n",
       "0  Home and Kitchen       5    CG   \n",
       "1  Home and Kitchen       5    CG   \n",
       "2  Home and Kitchen       5    CG   \n",
       "3  Home and Kitchen       1    CG   \n",
       "4  Home and Kitchen       5    CG   \n",
       "\n",
       "                                                text  \\\n",
       "0  Love this!  Well made, sturdy, and very comfor...   \n",
       "1  love it, a great upgrade from the original.  I...   \n",
       "2  This pillow saved my back. I love the look and...   \n",
       "3  Missing information on how to use it, but it i...   \n",
       "4  Very nice set. Good quality. We have had the s...   \n",
       "\n",
       "                                        text_no_stop  \\\n",
       "0  love ! well made , sturdy , comfortable . love...   \n",
       "1  love , great upgrade original . 've mine coupl...   \n",
       "2        pillow saved back . love look feel pillow .   \n",
       "3    missing information use , great product price !   \n",
       "4           nice set . good quality . set two months   \n",
       "\n",
       "                                       text_no_punct  \n",
       "0  love this  well made sturdy and very comfortab...  \n",
       "1  love it a great upgrade from the original  ive...  \n",
       "2  this pillow saved my back i love the look and ...  \n",
       "3  missing information on how to use it but it is...  \n",
       "4  very nice set good quality we have had the set...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add a column with the stop words for each review removed and the punctuation for each review removed\n",
    "reviews_df['text_no_stop'] = reviews_df['text'].apply(lambda s: ' '.join([token for token in word_tokenize(s.lower()) if token not in stopwords]))\n",
    "reviews_df['text_no_punct'] = reviews_df['text'].apply(lambda s: s.lower().translate(str.maketrans('', '', string.punctuation)))\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we tokenize the words, making each word a unit, remove stop words (common words that don't differentiate the text well)\n",
    "# Next we lemmatize the words, meaning break them down into their root meaning, thus words that come from the same root will be treated as the same\n",
    "def preprocess_text(s):\n",
    "    tokens = word_tokenize(s.lower())\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "    processed_text = ' '.join(lemmatized_tokens)\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a new column called lemma_text that applies the preprocess_text function to the text_no_punct column\n",
    "reviews_df['lemma_text'] = reviews_df['text_no_punct'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_no_stop</th>\n",
       "      <th>text_no_punct</th>\n",
       "      <th>lemma_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>neg_sentiment</th>\n",
       "      <th>pos_sentiment</th>\n",
       "      <th>neu_sentiment</th>\n",
       "      <th>comp_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home and Kitchen</td>\n",
       "      <td>5</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
       "      <td>love ! well made , sturdy , comfortable . love...</td>\n",
       "      <td>love this  well made sturdy and very comfortab...</td>\n",
       "      <td>love well made sturdy comfortable love itvery ...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.15, 'pos': 0.85, 'compou...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.9517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home and Kitchen</td>\n",
       "      <td>5</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I...</td>\n",
       "      <td>love , great upgrade original . 've mine coupl...</td>\n",
       "      <td>love it a great upgrade from the original  ive...</td>\n",
       "      <td>love great upgrade original ive mine couple year</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.321, 'pos': 0.679, 'comp...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.321</td>\n",
       "      <td>0.8910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home and Kitchen</td>\n",
       "      <td>5</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and...</td>\n",
       "      <td>pillow saved back . love look feel pillow .</td>\n",
       "      <td>this pillow saved my back i love the look and ...</td>\n",
       "      <td>pillow saved back love look feel pillow</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.417, 'pos': 0.583, 'comp...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.417</td>\n",
       "      <td>0.7906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home and Kitchen</td>\n",
       "      <td>1</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it i...</td>\n",
       "      <td>missing information use , great product price !</td>\n",
       "      <td>missing information on how to use it but it is...</td>\n",
       "      <td>missing information use great product price</td>\n",
       "      <td>{'neg': 0.214, 'neu': 0.388, 'pos': 0.398, 'co...</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.4404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home and Kitchen</td>\n",
       "      <td>5</td>\n",
       "      <td>CG</td>\n",
       "      <td>Very nice set. Good quality. We have had the s...</td>\n",
       "      <td>nice set . good quality . set two months</td>\n",
       "      <td>very nice set good quality we have had the set...</td>\n",
       "      <td>nice set good quality set two month</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.467, 'pos': 0.533, 'comp...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.6908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           category  rating label  \\\n",
       "0  Home and Kitchen       5    CG   \n",
       "1  Home and Kitchen       5    CG   \n",
       "2  Home and Kitchen       5    CG   \n",
       "3  Home and Kitchen       1    CG   \n",
       "4  Home and Kitchen       5    CG   \n",
       "\n",
       "                                                text  \\\n",
       "0  Love this!  Well made, sturdy, and very comfor...   \n",
       "1  love it, a great upgrade from the original.  I...   \n",
       "2  This pillow saved my back. I love the look and...   \n",
       "3  Missing information on how to use it, but it i...   \n",
       "4  Very nice set. Good quality. We have had the s...   \n",
       "\n",
       "                                        text_no_stop  \\\n",
       "0  love ! well made , sturdy , comfortable . love...   \n",
       "1  love , great upgrade original . 've mine coupl...   \n",
       "2        pillow saved back . love look feel pillow .   \n",
       "3    missing information use , great product price !   \n",
       "4           nice set . good quality . set two months   \n",
       "\n",
       "                                       text_no_punct  \\\n",
       "0  love this  well made sturdy and very comfortab...   \n",
       "1  love it a great upgrade from the original  ive...   \n",
       "2  this pillow saved my back i love the look and ...   \n",
       "3  missing information on how to use it but it is...   \n",
       "4  very nice set good quality we have had the set...   \n",
       "\n",
       "                                          lemma_text  \\\n",
       "0  love well made sturdy comfortable love itvery ...   \n",
       "1   love great upgrade original ive mine couple year   \n",
       "2            pillow saved back love look feel pillow   \n",
       "3        missing information use great product price   \n",
       "4                nice set good quality set two month   \n",
       "\n",
       "                                           sentiment  neg_sentiment  \\\n",
       "0  {'neg': 0.0, 'neu': 0.15, 'pos': 0.85, 'compou...          0.000   \n",
       "1  {'neg': 0.0, 'neu': 0.321, 'pos': 0.679, 'comp...          0.000   \n",
       "2  {'neg': 0.0, 'neu': 0.417, 'pos': 0.583, 'comp...          0.000   \n",
       "3  {'neg': 0.214, 'neu': 0.388, 'pos': 0.398, 'co...          0.214   \n",
       "4  {'neg': 0.0, 'neu': 0.467, 'pos': 0.533, 'comp...          0.000   \n",
       "\n",
       "   pos_sentiment  neu_sentiment  comp_sentiment  \n",
       "0          0.850          0.150          0.9517  \n",
       "1          0.679          0.321          0.8910  \n",
       "2          0.583          0.417          0.7906  \n",
       "3          0.398          0.388          0.4404  \n",
       "4          0.533          0.467          0.6908  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign the negative, positive, neutral, and composite sentiment values to columns\n",
    "sent_analyzer = SentimentIntensityAnalyzer()\n",
    "reviews_df['sentiment'] = reviews_df['lemma_text'].apply(lambda s: sent_analyzer.polarity_scores(s))\n",
    "reviews_df['neg_sentiment'] = reviews_df.sentiment.apply(lambda dc: dc['neg'])\n",
    "reviews_df['pos_sentiment'] = reviews_df.sentiment.apply(lambda dc: dc['pos'])\n",
    "reviews_df['neu_sentiment'] = reviews_df.sentiment.apply(lambda dc: dc['neu'])\n",
    "reviews_df['comp_sentiment'] = reviews_df.sentiment.apply(lambda dc: dc['compound'])\n",
    "\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "CG    62.784032\n",
       "OR    74.321231\n",
       "Name: num_words, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adds a column this the number of words in each review without punctuation\n",
    "reviews_df['num_words'] = reviews_df['text_no_punct'].apply(lambda s: len(s.split(' ')))\n",
    "# finds the average num of words in reviews grouped by whether the review is computer generated or not\n",
    "review_len_per_group = reviews_df.groupby('label')['num_words'].mean()\n",
    "review_len_per_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "CG    0.150475\n",
       "OR    0.160492\n",
       "Name: num_punc_stand, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_punc(text):\n",
    "    count = 0\n",
    "    for i in text:\n",
    "        if i in string.punctuation:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "reviews_df['num_punc_stand'] = reviews_df['text'].apply(count_punc) / reviews_df['num_words']\n",
    "num_punc_per_group = reviews_df.groupby('label')['num_punc_stand'].mean()\n",
    "num_punc_per_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorizes reviews based on overall sentiment\n",
    "def get_sentiment(review):\n",
    "    analysis = TextBlob(review)\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'Positive'\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Negative'\n",
    "\n",
    "# Apply sentiment analysis\n",
    "reviews_df['sentiment_category'] = reviews_df['text'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute Flesch-Kincaid Grade Level\n",
    "def compute_readability(review):\n",
    "    return textstat.flesch_kincaid_grade(review)\n",
    "\n",
    "# Apply the function to the 'review' column\n",
    "reviews_df['readability'] = reviews_df['text'].apply(compute_readability)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8606405341906764\n"
     ]
    }
   ],
   "source": [
    "## bag of words model \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(reviews_df['text_no_punct'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, reviews_df['label'], test_size=0.2, random_state=42)\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8712748856188945\n"
     ]
    }
   ],
   "source": [
    "# TFIDF model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(reviews_df['text_no_punct'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, reviews_df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "y_pred = naive_bayes.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = pd.DataFrame()\n",
    "tfidf_df['label'] = reviews_df['label']\n",
    "tfidf_df['text'] = reviews_df['lemma_text']\n",
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, analyzer='word', max_features=2000, tokenizer=word_tokenize)\n",
    "tfidf_X = tfidf.fit_transform(tfidf_df['text']).toarray()\n",
    "\n",
    "all_X = pd.concat([reviews_df[reviews_df.columns[-8:]], pd.DataFrame(tfidf_X)], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<32345x51256 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1351704 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_X['sentiment_category'] = all_X['sentiment_category'].apply(lambda x: 0 if x == 'Negative' else 2 if x == 'Positive' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vikram/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['int', 'str']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to MultinomialNB (input X)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [85]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(all_X, reviews_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m], test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      3\u001b[0m naive_bayes \u001b[38;5;241m=\u001b[39m MultinomialNB()\n\u001b[0;32m----> 4\u001b[0m \u001b[43mnaive_bayes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m naive_bayes\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m      8\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:690\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    688\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    689\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_counters(n_classes, n_features)\n\u001b[0;32m--> 690\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_alpha()\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_feature_log_prob(alpha)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:863\u001b[0m, in \u001b[0;36mMultinomialNB._count\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_count\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, Y):\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;124;03m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m     \u001b[43mcheck_non_negative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMultinomialNB (input X)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m safe_sparse_dot(Y\u001b[38;5;241m.\u001b[39mT, X)\n\u001b[1;32m    865\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_count_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m Y\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1249\u001b[0m, in \u001b[0;36mcheck_non_negative\u001b[0;34m(X, whom)\u001b[0m\n\u001b[1;32m   1246\u001b[0m     X_min \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mmin()\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_min \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNegative values in data passed to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m whom)\n",
      "\u001b[0;31mValueError\u001b[0m: Negative values in data passed to MultinomialNB (input X)"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(all_X, reviews_df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "y_pred = naive_bayes.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative', 'Positive', 'Neutral'], dtype=object)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
