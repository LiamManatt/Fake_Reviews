{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/vrisandubey/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vrisandubey/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/vrisandubey/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/vrisandubey/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/vrisandubey/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(s):\n",
    "    tokens = word_tokenize(s.lower())\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "    processed_text = ' '.join(lemmatized_tokens)\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = pd.read_csv('../data/fake_reviews.csv')\n",
    "reviews_df = reviews_df.rename(columns = {'text_': 'text'})\n",
    "reviews_df['category'] = reviews_df['category'].apply(lambda s: s[:-2].replace('_', ' '))\n",
    "reviews_df['rating'] = reviews_df['rating'].astype(int)\n",
    "\n",
    "reviews_df['text_no_stop'] = reviews_df['text'].apply(lambda s: ' '.join([token for token in word_tokenize(s.lower()) if token not in stopwords]))\n",
    "reviews_df['text_no_punct'] = reviews_df['text'].apply(lambda s: s.lower().translate(str.maketrans('', '', string.punctuation)))\n",
    "\n",
    "reviews_df['lemma_text'] = reviews_df['text_no_punct'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tfidf_df = pd.DataFrame()\n",
    "tfidf_df['label'] = reviews_df['label']\n",
    "tfidf_df['lemma_text'] = reviews_df['lemma_text']\n",
    "tfidf_df['text'] = reviews_df['text'] \n",
    "\n",
    "\n",
    "sent_analyzer = SentimentIntensityAnalyzer()\n",
    "tfidf_df['sentiment'] = reviews_df['lemma_text'].apply(lambda s: sent_analyzer.polarity_scores(s))\n",
    "tfidf_df['neg_sentiment'] = tfidf_df.sentiment.apply(lambda dc: dc['neg'])\n",
    "tfidf_df['pos_sentiment'] = tfidf_df.sentiment.apply(lambda dc: dc['pos'])\n",
    "tfidf_df['neu_sentiment'] = tfidf_df.sentiment.apply(lambda dc: dc['neu'])\n",
    "tfidf_df['comp_sentiment'] = tfidf_df.sentiment.apply(lambda dc: dc['compound'])\n",
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, analyzer='word', max_features=2000, tokenizer=word_tokenize)\n",
    "tfidf_X = tfidf.fit_transform(tfidf_df['lemma_text']).toarray()\n",
    "\n",
    "tfidf_val_df = pd.DataFrame(tfidf_X, columns=tfidf.get_feature_names_out())\n",
    "\n",
    "tfidf_val_df['label'] = tfidf_df.label\n",
    "tfidf_val_df['pos_sentiment'] = tfidf_df['pos_sentiment']\n",
    "tfidf_val_df['neg_sentiment'] = tfidf_df['neg_sentiment']\n",
    "tfidf_val_df['neu_sentiment'] = tfidf_df['neu_sentiment']\n",
    "tfidf_val_df['comp_sentiment'] = tfidf_df['comp_sentiment']\n",
    "tfidf_val_df['rating_sentiment_diff'] = np.abs(reviews_df['rating'] - tfidf_df['pos_sentiment'] * 5)\n",
    "\n",
    "tfidf_X = tfidf_val_df.drop(columns=['label'])\n",
    "y = tfidf_val_df.label\n",
    "  \n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ensemble(models, X_train, y_train, X_test, y_test, weights):\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "    y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "\n",
    "    mdl_preds = []\n",
    "    for i, model in enumerate(models, 1):\n",
    "        model.fit(X_train, y_train_encoded)\n",
    "        preds = np.array(model.predict(X_test))\n",
    "        print(f'Model {i} Accuracy: {np.mean(preds == y_test_encoded)}')\n",
    "\n",
    "        mdl_preds.append(np.array(preds))\n",
    "    \n",
    "    tot_preds = np.zeros(X_test.shape[0], dtype=float)\n",
    "    for i, pred in enumerate(mdl_preds):\n",
    "        tot_preds += weights[i] * pred\n",
    "\n",
    "    final_preds = np.where(tot_preds > 0.5, 1, 0)\n",
    "    print(f'Ensemble Accuracy: {np.mean(final_preds == y_test_encoded)}')\n",
    "\n",
    "    return label_encoder.inverse_transform(final_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Accuracy: 0.8861135155187337\n",
      "Model 2 Accuracy: 0.8590330159515271\n",
      "Model 3 Accuracy: 0.8739953011005317\n",
      "Ensemble Accuracy:0.880178063558798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['CG', 'CG', 'OR', ..., 'CG', 'OR', 'OR'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Best_Parameters_XGB= {'colsample_bytree': 0.8, 'gamma': 2, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.8}\n",
    "Best_Parameters_CB= {'depth': 8, 'iterations': 800, 'l2_leaf_reg': 3, 'learning_rate': 0.1}\n",
    "\n",
    "models = [\n",
    "   lgb.LGBMClassifier(objective='binary', metric='binary_logloss', learning_rate= 0.05, max_depth=-1, n_estimators=800, num_leaves=63, verbose=0),\n",
    "   XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss', **Best_Parameters_XGB),\n",
    "   CatBoostClassifier(task_type='CPU', verbose=0, **Best_Parameters_CB)\n",
    "]\n",
    "\n",
    "run_ensemble(models, X_train, y_train, X_test, y_test, weights=[1/3, 1/3, 1/3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting CV with weights (1 / 6): [0.3670983510672348, 0.3164508244663826, 0.3164508244663826]\n",
      "Fold 1\n",
      "Model 1 Accuracy: 0.8752511980213326\n",
      "Model 2 Accuracy: 0.8441799350749729\n",
      "Model 3 Accuracy: 0.8610295254289689\n",
      "Ensemble Accuracy: 0.8682949451228938\n",
      "-----------------------------------------------------\n",
      "Fold 2\n",
      "Model 1 Accuracy: 0.8735507806461587\n",
      "Model 2 Accuracy: 0.8554645231102179\n",
      "Model 3 Accuracy: 0.863193692997372\n",
      "Ensemble Accuracy: 0.8679857783274076\n",
      "-----------------------------------------------------\n",
      "Fold 3\n",
      "Model 1 Accuracy: 0.8789611995671665\n",
      "Model 2 Accuracy: 0.8568557736899057\n",
      "Model 3 Accuracy: 0.8727778636574431\n",
      "Ensemble Accuracy: 0.8752511980213326\n",
      "-----------------------------------------------------\n",
      "Fold 4\n",
      "Model 1 Accuracy: 0.8735507806461587\n",
      "Model 2 Accuracy: 0.8540732725305302\n",
      "Model 3 Accuracy: 0.8704591126912969\n",
      "Ensemble Accuracy: 0.874169114237131\n",
      "-----------------------------------------------------\n",
      "Fold 5\n",
      "Model 1 Accuracy: 0.8715411964754985\n",
      "Model 2 Accuracy: 0.8460349358478899\n",
      "Model 3 Accuracy: 0.8639666099860875\n",
      "Ensemble Accuracy: 0.8670582779409491\n",
      "-----------------------------------------------------\n",
      "\n",
      "CV 1 Mean Accuracy: 0.8705518627299428\n",
      "Overall Best Accuracy: 0.8705518627299428 with weights = [0.3670983510672348, 0.3164508244663826, 0.3164508244663826]\n",
      "\n",
      "Starting CV with weights (2 / 6): [0.42796595556564315, 0.2860170222171784, 0.2860170222171784]\n",
      "Fold 6\n",
      "Model 1 Accuracy: 0.8752511980213326\n",
      "Model 2 Accuracy: 0.8441799350749729\n",
      "Model 3 Accuracy: 0.8610295254289689\n",
      "Ensemble Accuracy: 0.8682949451228938\n",
      "-----------------------------------------------------\n",
      "Fold 7\n",
      "Model 1 Accuracy: 0.8735507806461587\n",
      "Model 2 Accuracy: 0.8554645231102179\n",
      "Model 3 Accuracy: 0.863193692997372\n",
      "Ensemble Accuracy: 0.8679857783274076\n",
      "-----------------------------------------------------\n",
      "Fold 8\n",
      "Model 1 Accuracy: 0.8789611995671665\n",
      "Model 2 Accuracy: 0.8568557736899057\n",
      "Model 3 Accuracy: 0.8727778636574431\n",
      "Ensemble Accuracy: 0.8752511980213326\n",
      "-----------------------------------------------------\n",
      "Fold 9\n",
      "Model 1 Accuracy: 0.8735507806461587\n",
      "Model 2 Accuracy: 0.8540732725305302\n",
      "Model 3 Accuracy: 0.8704591126912969\n",
      "Ensemble Accuracy: 0.874169114237131\n",
      "-----------------------------------------------------\n",
      "Fold 10\n",
      "Model 1 Accuracy: 0.8715411964754985\n",
      "Model 2 Accuracy: 0.8460349358478899\n",
      "Model 3 Accuracy: 0.8639666099860875\n",
      "Ensemble Accuracy: 0.8670582779409491\n",
      "-----------------------------------------------------\n",
      "\n",
      "CV 2 Mean Accuracy: 0.8705518627299428\n",
      "Overall Best Accuracy: 0.8705518627299428 with weights = [0.3670983510672348, 0.3164508244663826, 0.3164508244663826]\n",
      "\n",
      "Starting CV with weights (3 / 6): [0.45424368287426486, 0.27287815856286757, 0.27287815856286757]\n",
      "Fold 11\n",
      "Model 1 Accuracy: 0.8752511980213326\n",
      "Model 2 Accuracy: 0.8441799350749729\n",
      "Model 3 Accuracy: 0.8610295254289689\n",
      "Ensemble Accuracy: 0.8682949451228938\n",
      "-----------------------------------------------------\n",
      "Fold 12\n",
      "Model 1 Accuracy: 0.8735507806461587\n",
      "Model 2 Accuracy: 0.8554645231102179\n",
      "Model 3 Accuracy: 0.863193692997372\n",
      "Ensemble Accuracy: 0.8679857783274076\n",
      "-----------------------------------------------------\n",
      "Fold 13\n",
      "Model 1 Accuracy: 0.8789611995671665\n",
      "Model 2 Accuracy: 0.8568557736899057\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m val_y \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39miloc[val_index]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m final_preds \u001b[38;5;241m=\u001b[39m \u001b[43mrun_ensemble\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-----------------------------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m final_accs\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(final_preds \u001b[38;5;241m==\u001b[39m val_y))\n",
      "Cell \u001b[0;32mIn[40], line 8\u001b[0m, in \u001b[0;36mrun_ensemble\u001b[0;34m(models, X_train, y_train, X_test, y_test, weights)\u001b[0m\n\u001b[1;32m      6\u001b[0m mdl_preds \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(models, \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_encoded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(model\u001b[38;5;241m.\u001b[39mpredict(X_test))\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(preds\u001b[38;5;250m \u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;250m \u001b[39my_test_encoded)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/catboost/core.py:5220\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m   5218\u001b[0m     CatBoostClassifier\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m-> 5220\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5221\u001b[0m \u001b[43m          \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5222\u001b[0m \u001b[43m          \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/catboost/core.py:2400\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2397\u001b[0m allow_clear_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_clear_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2399\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining plots\u001b[39m\u001b[38;5;124m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params())]):\n\u001b[0;32m-> 2400\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_sets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2406\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2408\u001b[0m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[1;32m   2409\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object\u001b[38;5;241m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/catboost/core.py:1780\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[0;32m-> 1780\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[0;32m_catboost.pyx:4833\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:4882\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold = 0\n",
    "\n",
    "lgb_weights = np.random.uniform(0.33, 0.5, 6)\n",
    "best_acc = -1\n",
    "best_weight = []\n",
    "\n",
    "for i, w in enumerate(lgb_weights, 1):\n",
    "    final_accs = []\n",
    "    weights = [w, (1 - w) / 2, (1 - w) / 2]\n",
    "    print(f'Starting CV with weights ({i} / {len(lgb_weights)}): {weights}')\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        fold += 1\n",
    "        train_X = X_train.iloc[train_index]\n",
    "        train_y = y_train.iloc[train_index]\n",
    "\n",
    "        val_X = X_train.iloc[val_index]\n",
    "        val_y = y_train.iloc[val_index]\n",
    "\n",
    "        print(f'Fold {fold}')\n",
    "        final_preds = run_ensemble(models, train_X, train_y, val_X, val_y, weights)\n",
    "        print('-----------------------------------------------------')\n",
    "        \n",
    "        final_accs.append(np.mean(final_preds == val_y))\n",
    "\n",
    "    print()\n",
    "    mean_acc = np.mean(final_accs)\n",
    "    print(f'CV {i} Mean Accuracy: {mean_acc}')\n",
    "    \n",
    "    if mean_acc > best_acc:\n",
    "        best_acc = mean_acc\n",
    "        best_weight = weights\n",
    "    \n",
    "    print(f'Overall Best Accuracy: {best_acc} with weights = {best_weight}')\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
