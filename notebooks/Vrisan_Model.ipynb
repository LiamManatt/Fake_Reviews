{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe7b85ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/vikram/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vikram/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/vikram/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/vikram/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df9c38d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = pd.read_csv('../data/fake_reviews.csv')\n",
    "reviews_df = reviews_df.rename(columns = {'text_': 'text'})\n",
    "reviews_df['category'] = reviews_df['category'].apply(lambda s: s[:-2].replace('_', ' '))\n",
    "reviews_df['rating'] = reviews_df['rating'].astype(int)\n",
    "\n",
    "reviews_df['text_no_stop'] = reviews_df['text'].apply(lambda s: ' '.join([token for token in word_tokenize(s.lower()) if token not in stopwords]))\n",
    "reviews_df['text_no_punct'] = reviews_df['text'].apply(lambda s: s.lower().translate(str.maketrans('', '', string.punctuation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cd64bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(s):\n",
    "    tokens = word_tokenize(s.lower())\n",
    "    filtered_tokens = [token for token in tokens if token not in stopwords]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "    processed_text = ' '.join(lemmatized_tokens)\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bddca520",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df['lemma_text'] = reviews_df['text_no_punct'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e09c6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>text_no_stop</th>\n",
       "      <th>text_no_punct</th>\n",
       "      <th>lemma_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Home and Kitchen</td>\n",
       "      <td>5</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfor...</td>\n",
       "      <td>love ! well made , sturdy , comfortable . love...</td>\n",
       "      <td>love this  well made sturdy and very comfortab...</td>\n",
       "      <td>love well made sturdy comfortable love itvery ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home and Kitchen</td>\n",
       "      <td>5</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I...</td>\n",
       "      <td>love , great upgrade original . 've mine coupl...</td>\n",
       "      <td>love it a great upgrade from the original  ive...</td>\n",
       "      <td>love great upgrade original ive mine couple year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home and Kitchen</td>\n",
       "      <td>5</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and...</td>\n",
       "      <td>pillow saved back . love look feel pillow .</td>\n",
       "      <td>this pillow saved my back i love the look and ...</td>\n",
       "      <td>pillow saved back love look feel pillow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home and Kitchen</td>\n",
       "      <td>1</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it i...</td>\n",
       "      <td>missing information use , great product price !</td>\n",
       "      <td>missing information on how to use it but it is...</td>\n",
       "      <td>missing information use great product price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home and Kitchen</td>\n",
       "      <td>5</td>\n",
       "      <td>CG</td>\n",
       "      <td>Very nice set. Good quality. We have had the s...</td>\n",
       "      <td>nice set . good quality . set two months</td>\n",
       "      <td>very nice set good quality we have had the set...</td>\n",
       "      <td>nice set good quality set two month</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           category  rating label  \\\n",
       "0  Home and Kitchen       5    CG   \n",
       "1  Home and Kitchen       5    CG   \n",
       "2  Home and Kitchen       5    CG   \n",
       "3  Home and Kitchen       1    CG   \n",
       "4  Home and Kitchen       5    CG   \n",
       "\n",
       "                                                text  \\\n",
       "0  Love this!  Well made, sturdy, and very comfor...   \n",
       "1  love it, a great upgrade from the original.  I...   \n",
       "2  This pillow saved my back. I love the look and...   \n",
       "3  Missing information on how to use it, but it i...   \n",
       "4  Very nice set. Good quality. We have had the s...   \n",
       "\n",
       "                                        text_no_stop  \\\n",
       "0  love ! well made , sturdy , comfortable . love...   \n",
       "1  love , great upgrade original . 've mine coupl...   \n",
       "2        pillow saved back . love look feel pillow .   \n",
       "3    missing information use , great product price !   \n",
       "4           nice set . good quality . set two months   \n",
       "\n",
       "                                       text_no_punct  \\\n",
       "0  love this  well made sturdy and very comfortab...   \n",
       "1  love it a great upgrade from the original  ive...   \n",
       "2  this pillow saved my back i love the look and ...   \n",
       "3  missing information on how to use it but it is...   \n",
       "4  very nice set good quality we have had the set...   \n",
       "\n",
       "                                          lemma_text  \n",
       "0  love well made sturdy comfortable love itvery ...  \n",
       "1   love great upgrade original ive mine couple year  \n",
       "2            pillow saved back love look feel pillow  \n",
       "3        missing information use great product price  \n",
       "4                nice set good quality set two month  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1fb71c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CG</td>\n",
       "      <td>love well made sturdy comfortable love itvery ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CG</td>\n",
       "      <td>love great upgrade original ive mine couple year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CG</td>\n",
       "      <td>pillow saved back love look feel pillow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CG</td>\n",
       "      <td>missing information use great product price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CG</td>\n",
       "      <td>nice set good quality set two month</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0    CG  love well made sturdy comfortable love itvery ...\n",
       "1    CG   love great upgrade original ive mine couple year\n",
       "2    CG            pillow saved back love look feel pillow\n",
       "3    CG        missing information use great product price\n",
       "4    CG                nice set good quality set two month"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df = pd.DataFrame()\n",
    "tfidf_df['label'] = reviews_df['label']\n",
    "tfidf_df['text'] = reviews_df['lemma_text']\n",
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "417c3607",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf_df.drop(columns=['label'])\n",
    "y = tfidf_df['label']\n",
    "\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, analyzer='word', max_features=2000, tokenizer=word_tokenize)\n",
    "tfidf_X = tfidf.fit_transform(tfidf_df['text']).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97316d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.07533347, 0.        , 0.        , ..., 0.0904964 , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2406a991",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel = 'rbf')\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccc4ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = svm.predict(X_train)\n",
    "test_preds = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4fd16005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CG       0.97      0.97      0.97     16200\n",
      "          OR       0.97      0.97      0.97     16145\n",
      "\n",
      "    accuracy                           0.97     32345\n",
      "   macro avg       0.97      0.97      0.97     32345\n",
      "weighted avg       0.97      0.97      0.97     32345\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "329f92d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CG       0.89      0.86      0.88      4016\n",
      "          OR       0.87      0.90      0.88      4071\n",
      "\n",
      "    accuracy                           0.88      8087\n",
      "   macro avg       0.88      0.88      0.88      8087\n",
      "weighted avg       0.88      0.88      0.88      8087\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6666173f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Training C = 0.001\n",
      "[LibSVM]................\n",
      "Warning: using -h 0 may be faster\n",
      "*\n",
      "optimization finished, #iter = 16145\n",
      "obj = -31.919241, rho = -0.823455\n",
      "nSV = 32290, nBSV = 32290\n",
      "Total nSV = 32290\n",
      "Done Training...Starting to predict...\n"
     ]
    }
   ],
   "source": [
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "for C in [0.001, 0.01, 0.1]:\n",
    "    print(f'Started Training C = {C}')\n",
    "    svm = SVC(kernel = 'rbf', C=C, verbose=True)\n",
    "    svm.fit(X_train, y_train)\n",
    "    print('Done Training...Starting to predict...')\n",
    "    train_preds = svm.predict(X_train)\n",
    "    test_preds = svm.predict(X_test)\n",
    "    \n",
    "    train_accs.append(np.mean((np.array(y_train) == train_preds)))\n",
    "    test_accs.append(np.mean((np.array(y_test) == test_preds)))\n",
    "    print(f'Training Accuracy: {train_accs[-1]}')\n",
    "    print(f'Test Accuracy: {test_accs[-1]}')\n",
    "    print('Done Predicting')\n",
    "    \n",
    "    print(f'Done with C = {C}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d6a384e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Info] Number of positive: 16145, number of negative: 16200\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.241273 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 157388\n",
      "[LightGBM] [Info] Number of data points in the train set: 32345, number of used features: 1999\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499150 -> initscore=-0.003401\n",
      "[LightGBM] [Info] Start training from score -0.003401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(feature_fraction=0.9, learning_rate=0.05,\n",
       "               metric='binary_logloss', objective='binary')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_mdl = lgb.LGBMClassifier(\n",
    "    boosting_type='gbdt',\n",
    "    objective='binary',\n",
    "    metric='binary_logloss',\n",
    "    num_leaves=31,\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=100\n",
    ")\n",
    "\n",
    "lgb_mdl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed325a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n"
     ]
    }
   ],
   "source": [
    "train_preds = lgb_mdl.predict(X_train)\n",
    "test_preds = lgb_mdl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88f5a8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CG       0.85      0.83      0.84     16200\n",
      "          OR       0.83      0.85      0.84     16145\n",
      "\n",
      "    accuracy                           0.84     32345\n",
      "   macro avg       0.84      0.84      0.84     32345\n",
      "weighted avg       0.84      0.84      0.84     32345\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5037d86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          CG       0.82      0.81      0.82      4016\n",
      "          OR       0.81      0.83      0.82      4071\n",
      "\n",
      "    accuracy                           0.82      8087\n",
      "   macro avg       0.82      0.82      0.82      8087\n",
      "weighted avg       0.82      0.82      0.82      8087\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c93f6c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
